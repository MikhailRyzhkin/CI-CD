# CI-CD

Спринт 2

ЗАДАЧА

```
1. Клонируем репозиторий, собираем его на сервере srv.
Исходники простого приложения можно взять здесь. Это простое приложение на Django с уже написанным Dockerfile. 
Приложение работает с PostgreSQL, в самом репозитории уже есть реализация docker-compose — её можно брать за 
референс при написании Helm-чарта. Необходимо склонировать репозиторий выше к себе в Git и настроить пайплайн 
с этапом сборки образа и отправки его в любой docker registry. Для пайплайнов можно использовать GitLab, 
Jenkins или GitHub Actions — кому что нравится. Рекомендуем GitLab.

2. Описываем приложение в Helm-чарт.
Описываем приложение в виде конфигов в Helm-чарте. По сути, там только два контейнера — с базой и приложением, 
так что ничего сложного в этом нет. Стоит хранить данные в БД с помощью PVC в Kubernetes.

3. Описываем стадию деплоя в Helm.
Настраиваем деплой стадию пайплайна. Применяем Helm-чарт в наш кластер. Нужно сделать так, чтобы наше приложение 
разворачивалось после сборки в Kubernetes и было доступно по бесплатному домену или на IP-адресе с выбранным портом.
Для деплоя должен использоваться свежесобранный образ. По возможности нужно реализовать сборку из тегов в Git, где 
тег репозитория в Git будет равен тегу собираемого образа. Чтобы создание такого тега запускало пайплайн на сборку 
образа c таким именем hub.docker.com/skillfactory/testapp:2.0.3.
```

РЕШЕНИЕ

Подзадача 1: Клонируем репозиторий, собираем его на сервере srv.
  - Клонируем указанный репозиторий тестового приложения. У нас это папка: django-pg-docker-tutorial
  - Дорабатываем приложение - выносим секретные данные по подключению к БД в папку "private_data" и вносим её 
  в гитигнор. Для примера, как выглядит этот файл - private.var.example. Исправляем ошибки.
  - Делаем исполняемыми скрипты в папке scripts:
  ```
  chmod +x test_deploy_app.sh
  chmod +x test_destroy_app.sh
  ```
  - тестово разворачиваем приложение на ноде srv в docker для дебагинга:
  ```
  cd .. && cd scripts && ./test_deploy_app.sh
  ```
  Видим удачное тестовое разворачивание:

  - удаляем тестовое разворачивание приложения:
  ```
  cd .. && cd scripts && ./test_destroy_app.sh
  ```

  - В рамках подзадачи в роли Docker registry будем использовать Dockerhub. Логинимся в Dockerhub.
  Docker login и создаёми там репозиторий для хранения артифакта сборки. В нашем случе это:
  mikhailrizhkin1/diplom

  - В качестве CI/CD будем использовать Gitlab-CI
  - Создаём репозиторий в gitlab.com под проект: https://gitlab.com/Mikhail_Ryz/diplom_skillfactory_ci-cd
  - Создаём в нём гитлаб-раннер по пути Settings-CI/CD-Runners и отключаем шарэд раннеры

  - На сервере srv, настраиваем Gitlab-Runner:
  ```
  gitlab-runner register --url https://gitlab.com --token <your_token>
  ```
  И если видим его зелённым цветом, то всё в порядке.

  - Создаём нужные нам переменные для хранения приватных данных и другой информации по пути Settings-CI/CD-Variables:

  - Описываем pipeline в стандартном .gitlab-ci.yml файле состоящий из двух стадий - сборки приложения из докерфайла и выкатка - деплой приложения. Пушим в него наш проект. Запускаем пробно pipeline.
  
  - Для разворачивания приложения в  кластера kubernetes пишем манифесты в каталоге "Kube-manifests".
  - Секретные данные кодируем и помещаем в манифест "credentials.yaml", а его в гитигнор.
  - Переходим в каталог с манифестами и деплоим приложение в ранее развёрнутый K8S кластер:
  ```
  kubectl apply -f .
  ``` 


Подзадача 2: Описываем приложение в Helm-чарт.
  - На базе нашего приложения м манифестов создаём Helm chart.
  - Для приложения создадим отдельный нэймспейс, куда будем его диплоить:
  ```
  kubectl create namespace diplom
  ```
  - Развернём наш Helm chart в кластере k8s
  ```
  helm upgrade --install -n diplom app-dpdt && kubectl get pods -n diplom -o wide 
  ```

Подзадача 3: Описываем стадию деплоя в Helm.
  - Упаковываем Helm chart в архив:
  ```
  helm package chart 
  ```
  - Копируем и пушим созданный архив и сам чарт в репозиторий GitLab c CI/CD
  - Разрабатываем второй стейдж ci для развёртывания приложения в кластере k8s новой версии нсновании изменения тэга
  То есть у нас тригер будет - тэг. 